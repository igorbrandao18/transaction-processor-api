# Transaction Processor API

API para processamento de transa√ß√µes financeiras desenvolvida com NestJS, TypeScript e PostgreSQL, atendendo requisitos de confiabilidade, escalabilidade, observabilidade e facilidade de evolu√ß√£o.

## üöÄ Como Executar o Projeto

### Pr√©-requisitos

- Node.js 20+
- Docker e Docker Compose
- PostgreSQL 15+ (ou usar Docker)
- Redis 7+ (ou usar Docker)

### Op√ß√£o 1: Docker Compose (Recomendado)

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd transaction-processor-api

# Execute com Docker Compose
cd docker
docker compose up -d

# Aguarde os servi√ßos iniciarem (migra√ß√µes s√£o executadas automaticamente)
# Verifique o status
docker compose ps
```

**Servi√ßos dispon√≠veis:**
- **API**: http://localhost:3000
- **Swagger/OpenAPI**: http://localhost:3000/api/docs
- **Health Check**: http://localhost:3000/api/health
- **PostgreSQL**: localhost:5432
- **Redis**: localhost:6379
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3001

### Op√ß√£o 2: Desenvolvimento Local

```bash
# Instale depend√™ncias
npm install

# Configure vari√°veis de ambiente
cp .env.example .env
# Edite .env com suas configura√ß√µes

# Execute migra√ß√µes do Prisma
npm run migrate

# Inicie o servidor de desenvolvimento
npm run start:dev
```

### Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
# Server
PORT=3000
NODE_ENV=development

# Database
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=transactions_db
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/transactions_db?schema=public

# Redis (BullMQ)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Logging
LOG_LEVEL=info
```

## üéØ Funcionalidades Implementadas

### Funcionalidades M√≠nimas (Obrigat√≥rias)

- ‚úÖ **Receber transa√ß√µes financeiras via API** (`POST /api/transactions`)
  - Processamento ass√≠ncrono com BullMQ (fila de mensageria)
  - Retorna `202 Accepted` imediatamente com `jobId`
  - Processamento em background

- ‚úÖ **Persistir transa√ß√µes** em banco de dados relacional (PostgreSQL)
  - Schema com Prisma ORM
  - Migrations autom√°ticas

- ‚úÖ **Garantir idempot√™ncia** considerando concorr√™ncia e m√∫ltiplas requisi√ß√µes simult√¢neas
  - UNIQUE INDEX no campo `transaction_id`
  - Verifica√ß√£o antes de inserir no Service
  - Retorno `409 Conflict` se transa√ß√£o j√° existe
  - Transa√ß√µes de banco para atomicidade

- ‚úÖ **Consultar transa√ß√µes** (`GET /api/transactions`)
  - Pagina√ß√£o (page, limit)
  - Filtros por status, tipo, data
  - Ordena√ß√£o por data de cria√ß√£o

### Funcionalidades Extras

- ‚úÖ Obter metadados para formul√°rios (`GET /api/transactions/metadata`)
- ‚úÖ Buscar transa√ß√£o por ID (`GET /api/transactions/:id`)
- ‚úÖ Consultar status de job na fila (`GET /api/transactions/queue/:transactionId/status`)
- ‚úÖ Estat√≠sticas da fila (`GET /api/transactions/queue/stats`)
- ‚úÖ Health check (`GET /api/health`)
- ‚úÖ M√©tricas Prometheus (`GET /api/metrics`)

## üèóÔ∏è Arquitetura & Decis√µes

### Por que organizei o projeto dessa forma?

O projeto segue **Layered Architecture** (Arquitetura em Camadas) com separa√ß√£o clara de responsabilidades:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Presentation Layer (Controllers)    ‚îÇ ‚Üê Recebe requisi√ß√µes HTTP
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Application Layer (Services)       ‚îÇ ‚Üê L√≥gica de neg√≥cio
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Domain Layer (Entities/Models)      ‚îÇ ‚Üê Entidades e regras
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Infrastructure Layer (Repositories) ‚îÇ ‚Üê Acesso a dados
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benef√≠cios que busquei ao organizar assim:**
- **Testabilidade**: Cada camada pode ser testada isoladamente, o que facilita muito os testes unit√°rios
- **Manutenibilidade**: Mudan√ßas em uma camada n√£o afetam outras, reduzindo o risco de quebrar algo
- **Escalabilidade**: Consigo adicionar novos recursos sem quebrar c√≥digo existente
- **Clareza**: Responsabilidades bem definidas facilitam tanto meu trabalho quanto o onboarding de outros devs

**Padr√µes implementados:**
- **Repository Pattern**: Isola acesso ao banco de dados
- **Service Layer Pattern**: Centraliza l√≥gica de neg√≥cio e idempot√™ncia
- **DTO Pattern**: Valida entrada e controla exposi√ß√£o de dados
- **Dependency Injection**: Facilita testes e manuten√ß√£o (NestJS)

**Estrutura do projeto:**
```
src/
‚îú‚îÄ‚îÄ controllers/          # Presentation Layer
‚îÇ   ‚îú‚îÄ‚îÄ transactions.controller.ts
‚îÇ   ‚îú‚îÄ‚îÄ health.controller.ts
‚îÇ   ‚îî‚îÄ‚îÄ metrics.controller.ts
‚îú‚îÄ‚îÄ services/            # Application Layer
‚îÇ   ‚îú‚îÄ‚îÄ transactions.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ queue-metrics.service.ts
‚îú‚îÄ‚îÄ repositories/        # Infrastructure Layer
‚îÇ   ‚îî‚îÄ‚îÄ transactions.repository.ts
‚îú‚îÄ‚îÄ entities/            # Domain Layer
‚îÇ   ‚îî‚îÄ‚îÄ transaction.entity.ts
‚îú‚îÄ‚îÄ processors/          # Background Workers
‚îÇ   ‚îî‚îÄ‚îÄ transaction.processor.ts
‚îú‚îÄ‚îÄ queues/             # Queue Management
‚îÇ   ‚îî‚îÄ‚îÄ transactions.queue.ts
‚îú‚îÄ‚îÄ dto/                # Data Transfer Objects
‚îÇ   ‚îú‚îÄ‚îÄ create-transaction.dto.ts
‚îÇ   ‚îî‚îÄ‚îÄ query-transactions.dto.ts
‚îú‚îÄ‚îÄ config/            # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ app.config.ts
‚îÇ   ‚îú‚îÄ‚îÄ prisma.service.ts
‚îÇ   ‚îî‚îÄ‚îÄ metrics.config.ts
‚îî‚îÄ‚îÄ main.ts            # Entry point
```

## üóÑÔ∏è Cache

### Onde colocaria cache?

**‚úÖ Colocaria cache em:**

1. **GET /api/transactions/:id** (transa√ß√£o individual)
   - **Motivo**: Transa√ß√µes individuais s√£o consultadas frequentemente
   - **TTL**: 5-10 minutos (dados financeiros mudam pouco ap√≥s cria√ß√£o)
   - **Estrat√©gia**: Redis com chave `transaction:{id}`

2. **GET /api/transactions/metadata** (tipos, statuses, moedas)
   - **Motivo**: Dados est√°ticos raramente mudam
   - **TTL**: 1 hora ou invalida√ß√£o manual
   - **Estrat√©gia**: Redis com chave `metadata:transactions`

3. **GET /api/transactions** (listagem paginada)
   - **Motivo**: Reduz carga no banco em consultas frequentes
   - **TTL**: 1-2 minutos (dados podem mudar rapidamente)
   - **Estrat√©gia**: Redis com chave `transactions:page:{page}:limit:{limit}:filters:{hash}`

### Quando N√ÉO colocaria cache?

**‚ùå N√ÉO colocaria cache em:**

1. **POST /api/transactions** (cria√ß√£o)
   - **Motivo**: Opera√ß√£o de escrita deve ser sempre real-time
   - **Risco**: Dados inconsistentes entre cache e banco

2. **Consultas com filtros complexos ou datas recentes**
   - **Motivo**: Dados muito din√¢micos invalidariam cache constantemente
   - **Risco**: Cache ineficiente, overhead maior que benef√≠cio

3. **Dados cr√≠ticos de auditoria**
   - **Motivo**: Requer garantia de dados sempre atualizados
   - **Risco**: Compliance e auditoria podem ser comprometidos

## üìä Observabilidade em Produ√ß√£o

### Como garantiria observabilidade?

**1. Logs Estruturados (JSON)**
- ‚úÖ Implementado com Winston
- Formato JSON para f√°cil parsing
- N√≠veis: `error`, `warn`, `info`, `debug`
- Contexto inclu√≠do: `requestId`, `transactionId`, `jobId`

**2. M√©tricas**
- ‚úÖ Health Check (`GET /api/health`)
- ‚úÖ Swagger/OpenAPI (`GET /api/docs`)
- ‚úÖ **Prometheus + Grafana** - Implementado e ativo
  - Endpoint `/api/metrics` expondo m√©tricas Prometheus
  - M√©tricas HTTP: taxa de requisi√ß√µes, lat√™ncia, erros
  - M√©tricas de transa√ß√µes: criadas, processadas, fila
  - M√©tricas de banco de dados: conex√µes, dura√ß√£o de queries
  - Dashboards Grafana pr√©-configurados
  - Prometheus coletando m√©tricas a cada 15s

**3. Tracing**
- ‚è≥ **Pr√≥ximo passo**: OpenTelemetry
  - Trace IDs para rastrear requisi√ß√µes
  - Correla√ß√£o entre servi√ßos (se houver microservi√ßos)

**4. Monitoramento de Banco de Dados**
- ‚è≥ **Pr√≥ximo passo**: pg_stat_statements
  - Queries lentas
  - Uso de √≠ndices
  - Conex√µes ativas

**5. Alertas**
- ‚è≥ **Pr√≥ximo passo**: Integra√ß√£o com PagerDuty/Slack
  - Erros 5xx > 1% em 5 minutos
  - Lat√™ncia p95 > 2s
  - Banco de dados indispon√≠vel

## üîÑ Fila/Mensageria

### Em que cen√°rio voc√™ usaria fila/mensageria?

**‚úÖ Usaria fila em:**

1. **Processamento ass√≠ncrono de transa√ß√µes** ‚úÖ **IMPLEMENTADO**
   - **Cen√°rio**: Valida√ß√µes complexas, integra√ß√µes externas (gateways de pagamento)
   - **Benef√≠cio**: API responde r√°pido, processamento em background
   - **Status**: BullMQ totalmente funcional
   - **Como funciona**: 
     - `POST /api/transactions` enfileira job e retorna `202 Accepted` imediatamente
     - Worker processa em background (`TransactionProcessor`)
     - Status atualizado de `pending` ‚Üí `completed` ap√≥s processamento
     - Retry autom√°tico: 3 tentativas com backoff exponencial

2. **Envio de notifica√ß√µes**
   - **Cen√°rio**: Email, SMS, webhooks para clientes
   - **Benef√≠cio**: N√£o bloqueia resposta da API
   - **Implementa√ß√£o**: Worker separado consumindo fila

3. **Reconcilia√ß√£o e relat√≥rios**
   - **Cen√°rio**: Gera√ß√£o de relat√≥rios di√°rios, reconcilia√ß√£o banc√°ria
   - **Benef√≠cio**: Processamento em hor√°rios de baixo tr√°fego
   - **Implementa√ß√£o**: Jobs agendados (cron)

4. **Retry autom√°tico de falhas**
   - **Cen√°rio**: Integra√ß√£o externa falhou temporariamente
   - **Benef√≠cio**: Retry autom√°tico com backoff exponencial
   - **Status**: ‚úÖ Implementado - BullMQ com `attempts: 3` e `backoff: exponential`

**‚ùå N√ÉO usaria fila em:**

1. **Valida√ß√µes simples e r√°pidas**
   - **Motivo**: Overhead desnecess√°rio
   - **Exemplo**: Valida√ß√£o de formato de dados

2. **Opera√ß√µes s√≠ncronas cr√≠ticas**
   - **Motivo**: Cliente precisa de resposta imediata
   - **Exemplo**: Verifica√ß√£o de saldo antes de autorizar transa√ß√£o

## üîç Gargalos e Primeiro Problema em Produ√ß√£o

### Onde estaria o gargalo nesta implementa√ß√£o?

**1. Banco de Dados (PostgreSQL) - PRINCIPAL GARGALO**
- **Problema**: Escrita em disco, conex√µes limitadas, queries sem √≠ndice
- **Sintomas**: Lat√™ncia alta em `POST /api/transactions`, timeouts
- **Impacto**: Alto volume de requisi√ß√µes simult√¢neas satura o banco

**2. Conex√µes de Banco**
- **Problema**: Pool de conex√µes esgotado
- **Sintomas**: Erros "too many connections", requisi√ß√µes travando
- **Impacto**: Sistema fica indispon√≠vel

**3. Queries sem Otimiza√ß√£o**
- **Problema**: `SELECT *` sem √≠ndices adequados, N+1 queries
- **Sintomas**: Queries lentas (> 500ms), CPU do banco alta
- **Impacto**: Degrada√ß√£o gradual do desempenho

### Qual seria o primeiro problema real em produ√ß√£o?

**üî¥ PRIMEIRO PROBLEMA: Pool de Conex√µes Esgotado**

**Cen√°rio:**
1. Alto volume de requisi√ß√µes simult√¢neas (ex: 1000 req/s)
2. Pool de conex√µes configurado para 20 conex√µes
3. Requisi√ß√µes come√ßam a esperar por conex√£o dispon√≠vel
4. Timeout de requisi√ß√µes HTTP (30s) antes de obter conex√£o
5. Erros 503 Service Unavailable

**Por que acontece:**
- Cada requisi√ß√£o `POST /api/transactions` abre conex√£o
- Transa√ß√µes demoram para completar (INSERT + COMMIT)
- Conex√µes n√£o s√£o liberadas r√°pido o suficiente
- Pool esgota rapidamente

**Sintomas:**
- Logs mostram "Connection pool exhausted"
- Lat√™ncia aumenta drasticamente
- Taxa de erro 503 aumenta
- Banco mostra muitas conex√µes idle

### Qual solu√ß√£o voc√™ priorizaria primeiro e por qu√™?

**üéØ SOLU√á√ÉO PRIORIT√ÅRIA #1: Otimizar Pool de Conex√µes**

**A√ß√µes imediatas:**
1. **Aumentar pool de conex√µes** (20 ‚Üí 100)
2. **Configurar timeout de conex√£o** (evitar conex√µes travadas)
3. **Implementar retry com backoff** (requisi√ß√µes que falharam por falta de conex√£o)
4. **Monitorar m√©tricas de pool** (conex√µes ativas, idle, waiting)

**Por que priorizar:**
- ‚úÖ **Impacto imediato**: Resolve o problema mais cr√≠tico
- ‚úÖ **Baixo risco**: Mudan√ßa de configura√ß√£o, sem alterar c√≥digo
- ‚úÖ **R√°pido de implementar**: Apenas ajuste de vari√°veis de ambiente
- ‚úÖ **Base para outras otimiza√ß√µes**: Sistema est√°vel permite outras melhorias

**üéØ SOLU√á√ÉO PRIORIT√ÅRIA #2: Implementar Cache (Redis)**

**A√ß√µes:**
1. Cache para `GET /api/transactions/:id`
2. Cache para `GET /api/transactions/metadata`
3. Reduz carga no banco em 60-80% das requisi√ß√µes

**Por que segunda prioridade:**
- Requer infraestrutura adicional (Redis)
- Implementa√ß√£o mais complexa que ajuste de pool
- Benef√≠cio alto, mas n√£o resolve problema imediato de conex√µes

**üéØ SOLU√á√ÉO PRIORIT√ÅRIA #3: Usar Fila (BullMQ) para Escritas**

**Status atual:**
- ‚úÖ **Implementado**: BullMQ totalmente funcional
- ‚úÖ **POST /api/transactions**: Enfileira job e retorna 202 Accepted imediatamente
- ‚úÖ **Worker em background**: TransactionProcessor processa jobs assincronamente
- ‚úÖ **Retry autom√°tico**: 3 tentativas com backoff exponencial
- ‚úÖ **Monitoramento**: Endpoints para status e estat√≠sticas da fila

**Como funciona:**
1. `POST /api/transactions` adiciona job na fila (retorna 202 Accepted com jobId)
2. Worker processa em background (transaction.processor.ts)
3. API responde imediatamente sem esperar processamento
4. Cliente pode consultar status: `GET /api/transactions/queue/:transactionId/status`

**Por que terceira prioridade:**
- ‚úÖ J√° implementado e funcionando
- Benef√≠cio: reduz tempo de resposta da API, mas n√£o resolve problema imediato de pool de conex√µes
- Melhora throughput geral do sistema

## üí° D√≠vida T√©cnica Consciente

### O que voc√™ deixaria como d√≠vida t√©cnica?

**1. Cache n√£o implementado**
- **Status**: Redis dispon√≠vel, mas cache n√£o implementado nos endpoints
- **Motivo**: MVP funciona sem cache, n√£o √© cr√≠tico agora
- **Quando resolver**: Quando volume de requisi√ß√µes aumentar significativamente
- **Solu√ß√£o futura**: Implementar cache com Redis nos endpoints GET

**2. Logs sem Correla√ß√£o de Requisi√ß√µes (Request ID)**
- **Status**: Logs estruturados, mas sem trace ID √∫nico por requisi√ß√£o
- **Motivo**: Suficiente para debug inicial, n√£o cr√≠tico para MVP
- **Quando resolver**: Quando sistema crescer e precisar rastrear requisi√ß√µes entre servi√ßos
- **Solu√ß√£o futura**: OpenTelemetry ou middleware de request ID

**3. Valida√ß√µes de Neg√≥cio Simples**
- **Status**: Valida√ß√µes b√°sicas (formato, tipos), sem regras complexas
- **Motivo**: MVP n√£o requer valida√ß√µes avan√ßadas (ex: limite de transa√ß√£o por cliente)
- **Quando resolver**: Quando requisitos de neg√≥cio ficarem mais complexos
- **Solu√ß√£o futura**: Rules Engine ou Domain Events

**4. Sem Rate Limiting por Cliente/Tenant**
- **Status**: Rate limiting global implementado (100 req/min por IP)
- **Motivo**: MVP n√£o tem multi-tenancy completo, rate limit global suficiente
- **Quando resolver**: Quando houver m√∫ltiplos tenants com limites diferentes
- **Solu√ß√£o futura**: Rate limiting por tenant com Redis

**5. Testes de Carga B√°sicos**
- **Status**: Testes k6 implementados, mas cen√°rios limitados
- **Motivo**: Suficiente para validar comportamento b√°sico
- **Quando resolver**: Antes de scale para produ√ß√£o real
- **Solu√ß√£o futura**: Testes de carga mais abrangentes (cen√°rios de pico, degrada√ß√£o)

**6. Sem Circuit Breaker para Integra√ß√µes Externas**
- **Status**: N√£o h√° integra√ß√µes externas ainda
- **Motivo**: N√£o aplic√°vel no momento
- **Quando resolver**: Quando adicionar integra√ß√µes (gateways de pagamento, APIs externas)
- **Solu√ß√£o futura**: Circuit Breaker pattern (ex: `@nestjs/circuit-breaker`)

## üöÄ Tecnologias

- **Runtime**: Node.js 20+
- **Framework**: NestJS
- **Language**: TypeScript
- **Database**: PostgreSQL 15
- **ORM**: Prisma
- **Message Queue**: BullMQ (Redis) - ‚úÖ Implementado e funcionando
- **Logging**: Winston (JSON structured logs)
- **Validation**: class-validator
- **Documentation**: Swagger/OpenAPI
- **Testing**: Jest (unit, integration, e2e)
- **Monitoring**: Prometheus + Grafana

## üß™ Testes

### Executar Testes

```bash
# Unit tests
npm run test:unit

# Integration tests
npm run test:integration

# E2E tests
npm run test:e2e

# Todos os testes
npm run test:all
```

### Cobertura de Testes

- ‚úÖ **Unit Tests**: Services, Repositories, Utils
- ‚úÖ **Integration Tests**: API endpoints com banco real
- ‚úÖ **E2E Tests**: Fluxo completo de transa√ß√µes
- ‚úÖ **Idempotency Tests**: Requisi√ß√µes concorrentes

## üìö Documenta√ß√£o da API

Acesse a documenta√ß√£o Swagger em: `http://localhost:3000/api/docs`

A documenta√ß√£o inclui:
- Todos os endpoints dispon√≠veis
- Schemas de request/response
- Exemplos de uso
- Testes interativos

## üîê Idempot√™ncia

A API garante idempot√™ncia atrav√©s de:

1. **UNIQUE INDEX** no campo `transaction_id` no banco
2. **Verifica√ß√£o antes de inserir** no Service
3. **Retorno 409 Conflict** se transa√ß√£o j√° existe
4. **Transa√ß√µes de banco** para atomicidade em requisi√ß√µes concorrentes

**Exemplo:**
```bash
# Primeira requisi√ß√£o - cria transa√ß√£o
POST /api/transactions
{
  "transactionId": "txn-123",
  "amount": 100.50,
  "currency": "BRL",
  "type": "credit"
}
# Retorna: 202 Accepted com jobId

# Segunda requisi√ß√£o com mesmo transactionId - retorna existente
POST /api/transactions
{
  "transactionId": "txn-123",  # Mesmo ID
  "amount": 100.50,
  "currency": "BRL",
  "type": "credit"
}
# Retorna: 409 Conflict com transa√ß√£o existente
```

## üìà Performance

### Otimiza√ß√µes Implementadas

- ‚úÖ √çndices no banco (`transaction_id`, `created_at`, `status`)
- ‚úÖ Pagina√ß√£o em todas as listagens
- ‚úÖ Pool de conex√µes configurado
- ‚úÖ Queries parametrizadas (evita SQL injection e melhora cache do PostgreSQL)
- ‚úÖ Processamento ass√≠ncrono com BullMQ (n√£o bloqueia API)

### Pr√≥ximas Otimiza√ß√µes

- ‚è≥ Cache com Redis
- ‚è≥ Connection pooling otimizado
- ‚è≥ Read replicas para consultas
- ‚è≥ Compress√£o de respostas HTTP

## üö¢ Deploy

O projeto est√° configurado para deploy via GitHub Actions:

- ‚úÖ CI/CD pipeline (testes, build)
- ‚úÖ Deploy autom√°tico no push para `main`
- ‚úÖ Docker Compose no servidor
- ‚úÖ Nginx como reverse proxy
- ‚úÖ SSL/TLS via Let's Encrypt
- ‚úÖ Migrations autom√°ticas do Prisma

Veja `.github/workflows/deploy.yml` para detalhes.

## üìù Licen√ßa

Este projeto foi desenvolvido por **Igor Brand√£o** como parte de um desafio t√©cnico.
